--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@ -2141,6 +2141,11 @@ static inline bool btrfs_root_dead(const
 	return (root->root_item.flags & cpu_to_le64(BTRFS_ROOT_SUBVOL_DEAD)) != 0;
 }
 
+static inline u64 btrfs_root_id(const struct btrfs_root *root)
+{
+	return root->root_key.objectid;
+}
+
 /* struct btrfs_root_backup */
 BTRFS_SETGET_STACK_FUNCS(backup_tree_root, struct btrfs_root_backup,
 		   tree_root, 64);
@@ -2552,6 +2557,16 @@ int btrfs_get_extent_inline_ref_type(con
 
 u64 btrfs_csum_bytes_to_leaves(struct btrfs_fs_info *fs_info, u64 csum_bytes);
 
+/*
+ * Use this if we would be adding new items, as we could split nodes as we cow
+ * down the tree.
+ */
+static inline u64 btrfs_calc_insert_metadata_size(struct btrfs_fs_info *fs_info,
+						  unsigned num_items)
+{
+	return (u64)fs_info->nodesize * BTRFS_MAX_LEVEL * 2 * num_items;
+}
+
 static inline u64 btrfs_calc_trans_metadata_size(struct btrfs_fs_info *fs_info,
 						 unsigned num_items)
 {
--- a/fs/btrfs/delayed-inode.c
+++ b/fs/btrfs/delayed-inode.c
@@ -1501,7 +1501,7 @@ static void btrfs_release_dir_index_item
 	 */
 	trace_btrfs_space_reservation(fs_info, "transaction",
 				      trans->transid, bytes, 0);
-	btrfs_block_rsv_release(fs_info, trans->block_rsv, bytes, NULL);
+	btrfs_block_rsv_release(fs_info, trans->block_rsv, bytes);
 	ASSERT(trans->bytes_reserved >= bytes);
 	trans->bytes_reserved -= bytes;
 }
@@ -1514,9 +1514,12 @@ int btrfs_insert_delayed_dir_index(struc
 				   struct btrfs_disk_key *disk_key, u8 type,
 				   u64 index)
 {
+	const unsigned int leaf_data_size = BTRFS_LEAF_DATA_SIZE(fs_info);
 	struct btrfs_delayed_node *delayed_node;
 	struct btrfs_delayed_item *delayed_item;
 	struct btrfs_dir_item *dir_item;
+	bool reserve_leaf_space;
+	u32 data_len;
 	int ret;
 
 	delayed_node = btrfs_get_or_create_delayed_node(dir);
@@ -1551,7 +1554,7 @@ int btrfs_insert_delayed_dir_index(struc
 
 	mutex_lock(&delayed_node->mutex);
 	
-		/*
+	/*
 	 * First attempt to insert the delayed item. This is to make the error
 	 * handling path simpler in case we fail (-EEXIST). There's no risk of
 	 * any other task coming in and running the delayed item before we do
@@ -1559,7 +1562,7 @@ int btrfs_insert_delayed_dir_index(struc
 	 * delayed node's mutex and that mutex must also be locked before the
 	 * node's delayed items can be run.
 	 */
-	ret = __btrfs_add_delayed_item(delayed_node, delayed_item);
+	ret = __btrfs_add_delayed_item(delayed_node, delayed_item, BTRFS_DELAYED_INSERTION_ITEM);
 	if (unlikely(ret)) {
 		btrfs_err(trans->fs_info,
 "error adding delayed dir index item, name: %.*s, index: %llu, root: %llu, dir: %llu, dir->index_cnt: %llu, delayed_node->index_cnt: %llu, error: %d",
@@ -1582,7 +1585,7 @@ int btrfs_insert_delayed_dir_index(struc
 	}
 
 	if (reserve_leaf_space) {
-		ret = btrfs_delayed_item_reserve_metadata(trans, delayed_item);
+		ret = btrfs_delayed_item_reserve_metadata(trans,fs_info, delayed_item);
 		/*
 		 * Space was reserved for a dir index item insertion when we
 		 * started the transaction, so getting a failure here should be
--- a/fs/btrfs/delayed-inode.h
+++ b/fs/btrfs/delayed-inode.h
@@ -71,6 +71,17 @@ struct btrfs_delayed_node {
 	u64 index_cnt;
 	unsigned long flags;
 	int count;
+	/*
+	 * The size of the next batch of dir index items to insert (if this
+	 * node is from a directory inode). Protected by @mutex.
+	 */
+	u32 curr_index_batch_size;
+	/*
+	 * Number of leaves reserved for inserting dir index items (if this
+	 * node belongs to a directory inode). This may be larger then the
+	 * actual number of leaves we end up using. Protected by @mutex.
+	 */
+	u32 index_item_leaves;
 };
 
 struct btrfs_delayed_item {
